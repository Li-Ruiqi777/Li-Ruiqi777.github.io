<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>01 目标检测网络组成 | Hexo</title><meta name="author" content="Gearless Joe"><meta name="copyright" content="Gearless Joe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="目标检测网络组成 目前，目标检测的网络模型通常都遵循一个相似的结构，主要有3部分组成    Backbone network，即主干网络，是目标检测网络最为核心的部分，用来提取输入图片的特征。大多数时候，backbone选择的好坏，对检测性能影响是十分巨大的。 Neck network，即颈部网络（脖子网络？说实话，这个不翻译过来比较好……），Neck部分的主要作用就是将由backbone输出的特">
<meta property="og:type" content="article">
<meta property="og:title" content="01 目标检测网络组成">
<meta property="og:url" content="https://li-ruiqi777.github.io/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/01-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="目标检测网络组成 目前，目标检测的网络模型通常都遵循一个相似的结构，主要有3部分组成    Backbone network，即主干网络，是目标检测网络最为核心的部分，用来提取输入图片的特征。大多数时候，backbone选择的好坏，对检测性能影响是十分巨大的。 Neck network，即颈部网络（脖子网络？说实话，这个不翻译过来比较好……），Neck部分的主要作用就是将由backbone输出的特">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://li-ruiqi777.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-06-04T08:29:12.948Z">
<meta property="article:modified_time" content="2025-06-04T08:29:38.827Z">
<meta property="article:author" content="Gearless Joe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://li-ruiqi777.github.io/img/butterfly-icon.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://li-ruiqi777.github.io/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/01-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '01 目标检测网络组成',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Hexo</span></a><a class="nav-page-title" href="/"><span class="site-name">01 目标检测网络组成</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">01 目标检测网络组成</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-06-04T08:29:12.948Z" title="Created 2025-06-04 16:29:12">2025-06-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-06-04T08:29:38.827Z" title="Updated 2025-06-04 16:29:38">2025-06-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">11-深度学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="目标检测网络组成"><a href="#目标检测网络组成" class="headerlink" title="目标检测网络组成"></a>目标检测网络组成</h1><blockquote>
<p>目前，目标检测的网络模型通常都遵循一个相似的结构，主要有<strong>3部分</strong>组成</p>
</blockquote>
<p><img src="../../assets/06f07f08c2ce2b103a48a0781303d08f_v2-9c387bd12afb1ed62d9d0aab3f514f0b_720w.webp"></p>
<ul>
<li><strong>Backbone network</strong>，即<strong>主干网络</strong>，是目标检测网络最为核心的部分，用来提取输入图片的特征。大多数时候，backbone选择的好坏，对检测性能影响是十分巨大的。</li>
<li><strong>Neck network</strong>，即<strong>颈部网络</strong>（脖子网络？说实话，这个不翻译过来比较好……），Neck部分的主要作用就是将由backbone输出的特征进行整合（比如多尺度的融合）。其整合方式有很多，最为常见的就是FPN（Feature Pyramid Network），有关FPN的内容，我们会在展开介绍Neck的时候再次提到的。</li>
<li><strong>Detection head</strong>，即<strong>检测头</strong>，这一部分的作用就没什么特殊的含义了，就是若干卷积层进行预测，主要是改变特征图的形状。也有些工作里把head部分称为decoder（解码器）的，这种称呼不无道理，head部分就是在由前面网络输出的特征上去进行预测，约等于是从这些信息里解耦出来图像中物体的类别和位置信息。</li>
</ul>
<blockquote>
<p>我们可以为以上任意部分单独去设计一个模块，然后“插进去”即可。很多目标检测的优化工作就是这么来的，比如2018年的ECCV上的<strong>RFBNet</strong>，就是在SSD基础上，设计了RFB模块插进Neck部分，从而显著提升了模型性能。&#x3D;&#x3D;这就是模型的缝合&#x3D;&#x3D;</p>
</blockquote>
<h2 id="1-Backbone：目标检测网络的主体结构"><a href="#1-Backbone：目标检测网络的主体结构" class="headerlink" title="1.Backbone：目标检测网络的主体结构"></a>1.Backbone：目标检测网络的主体结构</h2><p>通常，为了实现从图像中检测目标的位置和类别，我们会先从图像中提取出些必要的特征信息，比如HOG特征，然后利用这些特征去实现定位和分类。而在深度学习这一块，这一任务就交由backbone网络来完成。深度学习的强大之处就在于其特征提取的能力，在很多任务上都超越了人工特征。</p>
<p>当然，这里提出的是什么样的特征，我们是无从得知的，毕竟深度学习的“黑盒子”特性至今还无法真正将其面纱揭开。</p>
<p>从某种意义上来说，如何设计好的<code>backbone</code>，更好地从图像中提取信息，是至关重要的，因为特征提取不好，自然会影响到后续的定位检测。</p>
<p>早在目标检测任务之前，深度学习技术就已经在图像分类领域中发挥了重大的作用，大力促进了这一领域的发展，尤其是在ResNet系列的工作问世后，图像分类任务几乎达到了一个顶峰——从ImageNet比赛不再举办这一点就可以窥见一斑。虽然后续这个领域还在陆陆续续地出现些新工作（如GhostNet、ShuffleNet、ResNet各种升级版本、EfficientNet家族等）、提供了很多新的idea，不过基本上已经不再是当年那种百花齐放的盛况了。</p>
<p>深度学习技术能够这么出色地完成图像分类任务，基本上也就表明了深度学习技术确实在图像特征提取这一块有着十分出色表现和巨大的潜力。</p>
<p>因此，Backbone这一部分通常就是将诸如VGG、ResNet等模型搬过来（去掉最后的global avgpooling和softmax层），这一部分的参数初始化就直接使用在ImageNet上训练好的参数。这一模式也就是后来所说的“<strong>ImageNet pretrained</strong>”概念。</p>
<p>不过，自从Kaiming He的《<strong>Rethinking ImageNet Pre-training</strong>》发表之后，这一概念似乎也就不是必要的了——一个目标检测模型完全可以随机初始化所有的参数，包括backbone网络的参数，只要训练足够久，也可以达到很高的性能。</p>
<p>当然，得是训练足够久，而且要精心调参，正所谓天下没有免费的午餐（早餐和晚餐也不免费。），既然设计了一个backbone，不想去ImageNet上预训练，那就得多花些时间和精力来训练detector了~因此，目前ImageNet pretrained的思想仍旧是主流，毕竟只需要在ImageNet上训练一次backbone，就可以永久使用了</p>
<p>Backbone恒久远，Pretrain一次永流传~</p>
<p>最后，简单介绍几个常用的backbone模型：</p>
<p><strong>首先是大型网络：</strong></p>
<p>1.<strong>VGG</strong>网络：《<strong>Very Deep Convolutional Networks for Large-Scale Image Recognition》。其中最常用的就是VGG-16.</strong></p>
<p>2.<strong>ResNet</strong>网络：《<strong>Deep Residual Learning for Image Recognition</strong>》。其中最常用的就是<strong>ResNet50</strong>和<strong>ResNet101</strong>。当任务需求很小的时候，也可以用ResNet18.</p>
<p>3.<strong>ResNeXT</strong>网络：《<strong>Aggregated residual transformations for deep neural networks</strong>》，这个我没有用过，但很多sota工作中都会使用，刷榜的小伙伴不妨考虑一下。</p>
<p>4.<strong>ResNet+DCN</strong>网络：这一网络主要是将DCN工作应用在ResNet网络上，DCN来源于这篇文章：《<strong>Deformable Convolutional Networks</strong>》。DCN是常用的涨点神器，不过似乎在实际部署的时候要复杂一些，刷榜的时候还是很值得一用。</p>
<p>5.<strong>DarkNet网络</strong>：常用的包括<strong>darknet19</strong>和<strong>darknet53</strong>，这两个网络分别来源于YOLOv2和YOLOv3两个工作中。其中darknet19对标的是vgg19，darknet53对标的是resnet101，但由于darknet本身是个很小众的深度学习框架，不受学术界关注，且这两个网络均是由darknet框架实现的，因此也就很少会在其他工作中看到这两个backbone。不过，笔者更偏爱darknet，也对其进行了复现，因为结构简洁，便于理解。</p>
<p>6.<strong>CSPResNet网络</strong>：出自于《<strong>CSPNet: A New Backbone that can Enhance Learning Capability of CNN</strong>》。CSP是一种很好用的结构，在减少参数量的同时，还能够提升模型性能，是不可多得的性价比极高的模块之一。像前一段时间的Scaled-YOLOv4就借鉴了这一工作的思想大幅度提升了YOLOv4的性能。不过，目前似乎也不是主流，仍旧无法撼动ResNet101和ResNet+DCN的刷榜地位。</p>
<p><strong>然后是轻量型网络：</strong></p>
<p>1.<strong>MobileNet</strong>：谷歌的工作，一共出了v1，v2，v3三个版本了，相较于上面那些以GPU为主要应用平台的大型网络，MobileNet则着眼于低性能的移动端平台，如手机、嵌入式设备等。</p>
<p>2.<strong>ShuffleNet</strong>：旷视的工作，一共出了v1和v2两个版本，同样是针对于低性能的移动端平台。</p>
<p>还有很多出色的backbone网络这里就不一一列举了，本文就只列出几个常用的，感兴趣的小伙伴可以自行查找更多的backbone网络。</p>
<hr>
<p>还有一个&#x3D;&#x3D;非常重要&#x3D;&#x3D;的地方，BackBone决定了每个特征图的感受野，感受野的大小需要和待检测物体的尺寸相匹配，这样才有足够的正样本，模型才能更好地训练。</p>
<p>比如现在检测的物体是8x8大小的，某层的特征图的感受野是16x16，那么这个物体很可能不能落在感受野中间，模型可能就不能有效学习学习。但如果某层的感受野是8x8，那么至少有一个单元能命中该目标，这保证了正样本的数量。</p>
<blockquote>
<p>BackBone的核心：能为检测提供若干种感受野和步长的组合，以满足对不同尺度物体的目标检测</p>
</blockquote>
<h2 id="2-Neck：更好地利用网络所提取的特征信息"><a href="#2-Neck：更好地利用网络所提取的特征信息" class="headerlink" title="2.Neck：更好地利用网络所提取的特征信息"></a>2.Neck：更好地利用网络所提取的特征信息</h2><p>上面已经目标检测模型中的backbone部分，其作用归根结底就是一句话：提取图像中有用的信息。当然，什么是有用的信息是一句很笼统的话，总之是这么个意思。然而，由于backbone网络毕竟是从<strong>图像分类</strong>（image classification）任务迁移过来的，其提取特征的模式<strong>可能不太适合与detection</strong>。因此，在我们最终从这些特征中得到图像中若干目标的类别信息（classification）和位置（location）信息之前，有必要对它们做一些处理。</p>
<p>这一部分，因为是在backbone之后，detection head之前，因此，被称为“Neck”。</p>
<p>相较于backbone常使用ImageNet Pretrained model，neck部分反倒没有什么说道。既然它的作用是将backbone的信息好好地整合一下，因此，研究者们自由发挥的空间也就会大得多了，很多模块被提出了出来。这里我们介绍几个常见的。</p>
<p>最有名的，莫过于<strong>FPN（Feature Pyramid Network）</strong>了：</p>
<p><img src="https://pic3.zhimg.com/80/v2-1452b84037849d115bcb9e0a2bd4a332_720w.webp" alt="img"></p>
<p>图中d是FPN的结构</p>
<p>在SSD之前，不论是Faster R-CNN还是YOLO，他们都只是在backbone输出的最后一层很粗糙的特征图（feature map）上去做检测的。在CNN中，有一个很关键的概念叫做“感受野”（receptive field），大抵的意思就是<strong>这一张特征图的pixel能包含原始图像中的少个像素</strong>。直观上来看，backbone最后输出的很粗糙的特征图——通常都是stride&#x3D;32，即经过了32倍降采样——具有很大的感受野，这对于大物体来说是很友好的，但对于小物体而言，过大的感受野且不说容易“失焦”，经过多次降采样，小物体的信息也很容易被丢失掉了。</p>
<p>为了解决这么个问题，SSD<strong>在三个不同大小的特征图上进行预测</strong>，即上图中的（c），但CNN随着网络深度的增加，每一层的特征图所携带的信息量和信息性质也不一样——浅层包含的细节信息、轮廓信息、位置信息等更多，深层包含的语义信息更多。因此，FPN的工作就是在检测前，先将多个尺度的特征图进行一次bottom-up的融合，也就是上图中的（d），这被证明是极其有效的特征融合方式，几乎成为了后来目标检测的标准模式之一。</p>
<p>除了FPN，还有SPP模块，这也是很常用的一个Neck结构，下图便是SPP的结构示意图。</p>
<p><img src="https://pic4.zhimg.com/80/v2-28ae9fc0fb4dae7d180236521e65d2b3_720w.webp" alt="img"></p>
<p>YOLOv3通过添加这一模块有效提升了模型的性能，而模型的计算量的增加几乎可以忽略不记。SPP的思想很简单，通过不同大小的maxpooling核来丰富特征图的感受野。这一模块在YOLOv3中是添加在stride&#x3D;32的特征图之后，FPN之前，后面讲到YOLOv3Spp网络的时候，我会详细介绍这一点的。因其极其简单的结构、有效的性能提升等高性价比特点，在后来的YOLOv4、PP-YOLO、Scaled-YOLOv4中都使用了SPP。</p>
<p>除此之外，还有：</p>
<ol>
<li><strong>RFB</strong>：出自《<strong>Receptive Field Block Net for Accurate and Fast Object Detection</strong>》</li>
<li><strong>ASPP</strong>：出自《<strong>DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs</strong>》</li>
<li><strong>SAM</strong>：出自《<strong>CBAM: Convolutional block attention module</strong>》</li>
<li><strong>PAN</strong>：出自《<strong>Path aggregation network for instance segmentation</strong>》。PAN是一个非常好用的特征融合方式，在FPN的bottom-up基础上又引入了top-down二次融合，有效地提升了模型性能。</li>
</ol>
<p>还有很多出色的Neck模块，这里就不一一展开细说了，感兴趣的读者可以自行上网搜索。</p>
<h2 id="3-Detection-head：负责检测与定位。"><a href="#3-Detection-head：负责检测与定位。" class="headerlink" title="3.Detection head：负责检测与定位。"></a>3.Detection head：负责检测与定位。</h2><p>一张图像，在经过了backbone和neck两部分的处理后，就可以准备进行最终的检测了。也许有人会好奇，经过两部分的处理后，网络输出的东西长什么样子呢，这里，笔者展示三张经由ShuffleNet和PAN处理后得到的三个尺度的特征热力图，如下所示：</p>
<p><img src="https://pic4.zhimg.com/80/v2-058f928c155e1d14ed8bfd7895d23c8b_720w.webp" alt="img"></p>
<p>stride&#x3D;8</p>
<p><img src="https://pic1.zhimg.com/80/v2-592841f633ecc7e640b2ea24c55cd254_720w.webp" alt="img"></p>
<p>stride&#x3D;16</p>
<p><img src="https://pic2.zhimg.com/80/v2-cce629218ef5e0ac1293f2384aee188d_720w.webp" alt="img"></p>
<p>stride&#x3D;32</p>
<p>然后是原图：</p>
<p><img src="https://pic2.zhimg.com/80/v2-7ed7f1b4d3e0594d9af158bc815249e9_720w.webp" alt="img"></p>
<p>摘取自VOC2007数据集</p>
<p>至于上面三张热力图都包含了怎样的信息就交给读者自己来分析吧。</p>
<p>随后，在这样的特征图上，<strong>通过添加几层卷积即可进行识别和定位</strong>。&#x3D;&#x3D;我觉得该层的作用就是改变特征图的形状&#x3D;&#x3D;。Detection head并不像前两部分那样，有那么多的说道和自由发挥的空间，这一部分通常就是普通的卷积，如下图的RetinaNet：</p>
<p><img src="https://pic4.zhimg.com/80/v2-1e36f51da0882652785752032089dc3b_720w.webp" alt="img"></p>
<p>RetinaNet的网络结构</p>
<p>RetinaNet最后的detection head部分就是三条并行的分支，每个分支右4层普通卷积堆叠而成。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://Li-Ruiqi777.github.io">Gearless Joe</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://li-ruiqi777.github.io/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/01-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90.html">https://li-ruiqi777.github.io/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/01-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/00-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" title="00 评价指标"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">00 评价指标</div></div><div class="info-2"><div class="info-item-1">目标检测中常见评价指标 这个链接总结的很好，看看这个链接： https://www.cnblogs.com/itmorn/p/14193729.html  1.目标检测的混淆矩阵目标检测也经常会使用到机器学习中的混淆矩阵的概念，下面解释该矩阵中各项在目标检测任务中的含义   首先明确一点，混淆矩阵是用于分类任务的，这里是把每个预测框是否属于GT作为类别。 每个被预测出的bbox都是正例  (1)真正例(True Positive, TP):正样本被预测正确的数量，每个样本需满足以下条件：  预测类别和标签类别一致 预测bbox和GT的IOU大于阈值，当有多个满足条件的bbox时，选择置信度最大的为TP，其余为FP  (2)假正例(False Positive, FP):负样本被预测成正样本的数量，每个样本需满足以下条件之一：  bbox与GT的IOU小于阈值 预测类别和标签类别不同  (3)假反例(False Negative, FN):正样本被预测成正负样本的数量，等价于：  没有别检测出的GT的个数  (4)真反例(True Negative,...</div></div></div></a><a class="pagination-related" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/BackBone.html" title="BackBone"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">BackBone</div></div><div class="info-2"><div class="info-item-1">BackBone在深度学习的论文中，经常见到Backbone这个单词，它代表着主干网络。这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，供后面的网络使用。这些网络经常使用的是resnet、VGG等已被证明有较强的特征提取能力的网络，而不是我们自己设计的网络。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。这就是常说的迁移学习因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。 举个例子，比如VGG的原始应用是给1000个种类进行分类，如果我们要利用VGG进行5个种类的分类的话，只需要重写原始网络中的那3个全连接层，改变输出向量的维度就可以了。在训练的时候可以锁定预先加载的VGG网络的所有参数，只训练自己新加的全连接层。这就叫迁移学习。 </div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Gearless Joe</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">179</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">25</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90"><span class="toc-number">1.</span> <span class="toc-text">目标检测网络组成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Backbone%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%BB%E4%BD%93%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">1.Backbone：目标检测网络的主体结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Neck%EF%BC%9A%E6%9B%B4%E5%A5%BD%E5%9C%B0%E5%88%A9%E7%94%A8%E7%BD%91%E7%BB%9C%E6%89%80%E6%8F%90%E5%8F%96%E7%9A%84%E7%89%B9%E5%BE%81%E4%BF%A1%E6%81%AF"><span class="toc-number">1.2.</span> <span class="toc-text">2.Neck：更好地利用网络所提取的特征信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Detection-head%EF%BC%9A%E8%B4%9F%E8%B4%A3%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D%E3%80%82"><span class="toc-number">1.3.</span> <span class="toc-text">3.Detection head：负责检测与定位。</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/02-YOLOv1.html" title="02 YOLOv1">02 YOLOv1</a><time datetime="2025-06-04T08:29:12.964Z" title="Created 2025-06-04 16:29:12">2025-06-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/04-YOLOv3.html" title="04 YOLOv3">04 YOLOv3</a><time datetime="2025-06-04T08:29:12.964Z" title="Created 2025-06-04 16:29:12">2025-06-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/03-YOLOv2.html" title="03 YOLOv2">03 YOLOv2</a><time datetime="2025-06-04T08:29:12.964Z" title="Created 2025-06-04 16:29:12">2025-06-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/05-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA.html" title="05 数据增强">05 数据增强</a><time datetime="2025-06-04T08:29:12.964Z" title="Created 2025-06-04 16:29:12">2025-06-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/11-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/06-YOLOv8.html" title="06 YOLOv8">06 YOLOv8</a><time datetime="2025-06-04T08:29:12.964Z" title="Created 2025-06-04 16:29:12">2025-06-04</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Gearless Joe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>